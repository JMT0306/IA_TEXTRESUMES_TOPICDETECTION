Este é o primeiro editorial que escrevo em parceria com alguém desde que assumi o cargo de editor da RECADM em 2017. Não porque eu precisei necessariamente de ajuda, mas porque muitos colegas estão surpresos com as habilidades da inteligência artificial do meu coautor, o ChatGPT.ChatGPT é uma ferramenta de processamento de linguagem natural, desenvolvida pela OpenAI. Ele é baseado em uma rede neural treinada com milhões de textos da internet, permitindo que ele gere textos de forma autônoma. Ele foi lançado há pouco mais de um mês e já tem mais de 700 artigos identificados por meio do Google Scholar, o que demonstra sua importância e utilidade na área de inteligência artificial e processamento de linguagem natural. Ele é usado para várias finalidades, tais como chatbots, geração automática de conteúdo, tradução automática, entre outras. Ele é uma das ferramentas de IA mais avançadas disponíveis no mercado, e seus desenvolvedores estão constantemente trabalhando para melhorar sua precisão e capacidade de compreensão do idioma natural. Devido à sua capacidade de escrever de forma coerente e inteligente, muitos colegas estão preocupados sobre como o uso do ChatGPT entre pesquisadores e estudantes pode afetar o meio acadêmico, levantando questões sobre como avaliar a integridade acadêmica a partir de agora. Por essa razão, neste editorial, farei uma brincadeira divertida chamada "Jogo da Imitação", onde o leitor terá que adivinhar quem escreveu os parágrafos. Será um desafio interessante para testar as habilidades de observação e análise do leitor, além de ser uma maneira divertida de explorar as capacidades da inteligência artificial do ChatGPT. Então, esteja preparado e divirta-se!O jogo da imitação, também conhecido como o teste de Turing, é um teste para medir a capacidade de uma máquina de se comunicar de forma indistinguível de um ser humano. O teste foi proposto pelo matemático britânico Alan Turing em 1950 e consiste em três participantes: um juiz humano, um humano que age como uma fonte de comunicação e uma máquina. O juiz tem que determinar, por meio de uma conversa escrita, qual dos dois participantes é a máquina. Se o juiz não consegue distinguir entre a comunicação humana e a da máquina, então a máquina é considerada como tendo passado no teste de Turing. Esse teste tem sido um importante marco na pesquisa sobre inteligência artificial e continua sendo um tópico importante na discussão sobre a relação entre máquinas e humanos.Apesar das brincadeiras, a preocupação dos colegas apresenta fundamento. Em artigo recente publicado na Nature, Else (2023) apontou que o ChatGPT conseguiu escrever resumos de artigos de pesquisa tão convincentes que os cientistas muitas vezes não conseguem identificá-los, de acordo com um estudo publicado no bioRxiv. Isso levanta preocupações sobre como a IA pode afetar a avaliação da integridade acadêmica e a confiança na ciência. Alguns pesquisadores estão preocupados com a perda do intermediário (humano) necessário para guiar a compreensão de tópicos complicados.Os pesquisadores pediram ao robô de chat ChatGPT para escrever 50 resumos de pesquisas médicas baseados em uma seleção publicada em várias revistas. Eles compararam esses resumos com os originais usando ferramentas de detecção de plágio e de saída de IA, e pediram a um grupo de pesquisadores médicos para identificar os resumos fabricados. Os resultados mostraram que os resumos gerados pelo ChatGPT passaram pelo verificador de plágio, em que 66% foram identificados pelo detector de saída de IA e apenas 68%, identificados corretamente pelos revisores humanos. Isso sugere que a IA é capaz de escrever resumos científicos convincentes e levanta questões sobre seus limites éticos e de uso aceitável.Já há também artigos publicados em coautoria com o ChatGPT (que até possui um ORCID), o que foi objeto de piada do autor (ver Figura 1). Em artigo publicado na Oncoscience (cuja qualidade desconheço), ChatGPT e Zhavoronkov (2022) demonstraram resultados inéditos em muitas tarefas anteriormente acessíveis apenas à inteligência humana. Os autores especularam sobre as aplicações da Rapamicina, no contexto do argumento filosófico de Pascal's Wager, comumente utilizadas para justificar a crença em Deus. Em resposta à consulta "Escreva uma perspectiva de pesquisa exaustiva sobre por que tomar Rapamicina pode ser mais benéfico do que não tomar Rapamicina a partir da perspectiva de Pascal's Wager", o ChatGPT forneceu os prós e contras do uso da Rapamicina considerando as evidências pré-clínicas de potencial prolongamento da vida em animais. Segundo os autores, eles demonstram o potencial do ChatGPT para produzir argumentos filosóficos complexos e não deve ser usado para qualquer uso fora da rotulagem da Rapamicina.Figura 1: Twitter de Alex Zhavoronkov sobre seu artigo coautorado pelo ChatGPTHá também editorais de periódicos já escritos com o ChatGPT. Em editorial recentemente publicado na Nurse Education in Practice, O'Connor e ChatGPT (2023) afirmam que discernir a escrita de um estudante da escrita de um robô de chat de IA poderá ser quase impossível. Isso pode ser especialmente problemático no nível de pós-graduação, onde teses e dissertações extensas e detalhadas são exigidas. Para lidar com isso, os autores sugerem usar tipos de avaliação mais diversos, tais como apresentações orais e exames clínicos estruturados objetivos, além de softwares de plágio mais sofisticados e educação sobre integridade acadêmica e valor do conhecimento adquirido.Independentemente dos perigos, as ferramentas do ChatGPT vêm sendo amplamente usadas na ciência. Hutson (2022) entrevistou, inclusive, alguns cientistas sobre o uso, cujos depoimentos, a meu ver, são chocantes:
"Eu acho que uso o GPT-3 quase todos os dias", diz o cientista da computação Hafsteinn Einarsson, na Universidade da Islândia, Reykjavik. Ele o usa para gerar feedback sobre os resumos de suas publicações. Em um exemplo que Einarsson compartilhou em uma conferência em junho, algumas sugestões do algoritmo foram inúteis, aconselhando-o a adicionar informações que já estavam incluídas em seu texto. Mas outras foram mais úteis, como "tornar a pergunta de pesquisa mais explícita no início do resumo". Pode ser difícil ver os defeitos em seu próprio manuscrito, diz Einarsson. "Ou você precisa dormir com isso por duas semanas, ou pode ter alguém olhando. E esse 'alguém' pode ser o GPT-3."
Alguns pesquisadores usam LLMs para gerar títulos de artigos ou para tornar o texto mais legível. Mina Lee, estudante de doutorado em ciência da computação na Universidade de Stanford, California, dá prompts ao GPT-3 como "usando essas palavras-chave, gere o título de um artigo". Para reescrever seções problemáticas, ela usa um assistente de escrita de IA chamado Wordtune, da AI21 Labs em Tel Aviv, Israel. "Eu escrevo um parágrafo e é basicamente como um despejo cerebral", ela diz. "Eu só clico em 'Rewrite' até encontrar uma versão mais limpa que goste."
    Diante de tais ameaças, a academia já vem combatendo o uso de tais ferramentas. Por exemplo, a Conferência Internacional de Aprendizado de Máquina proibiu o uso de texto gerado por modelos de linguagem de grande escala (LLM), como o ChatGPT, a menos que o texto gerado seja apresentado como parte da análise experimental do trabalho. Isso desencadeou uma discussão nas redes sociais sobre como as pessoas lidarão com a crescente utilização desses modelos, que podem ajudar a comunicar ideias, mas também podem "pegar emprestado" ou plagiá-las (ver reportagem original em Venture Beat).
    Apesar dos perigos que o ChatGPT pode representar para a ciência, ele também pode ser visto como uma ferramenta valiosa que pode liberar os cientistas da tarefa árdua e nem sempre central da escrita. Com a capacidade de gerar texto de forma articulada e inteligente, o ChatGPT pode ajudar os cientistas a economizar tempo e esforço na redação de resumos, artigos e outros documentos científicos.
    Isso permite que os cientistas se concentrem em sua verdadeira paixão: a geração de novas ideias e o processo criativo. Ao invés de gastar horas escrevendo e revisando artigos, os cientistas podem usar esse tempo para desenvolver suas teorias e conduzir mais experimentos. Além disso, como


a escrita automatizada pode ser menos suscetível a erros humanos, pode haver menos erros e incongruências nos artigos científicos gerados pelo ChatGPT.
    É importante notar, no entanto, que o ChatGPT não é uma solução mágica para todos os problemas de escrita científica. Ele não substitui completamente a necessidade de revisão e edição humanas, e é fundamental que os cientistas continuem a seguir as normas éticas e acadêmicas ao utilizar essa ferramenta. No entanto, se usado de forma apropriada, o ChatGPT pode ser uma ferramenta poderosa para ajudar os cientistas a se concentrar em sua verdadeira paixão: a geração de novas ideias e o processo criativo.
    Ainda é cedo para prever exatamente como a inteligência artificial transformará a ciência, mas já é possível constatar que essa tecnologia terá um impacto significativo. A capacidade de gerar texto de forma articulada e inteligente, como é o caso do ChatGPT, é apenas um exemplo de como a IA pode ajudar os cientistas a economizar tempo e esforço na escrita de documentos científicos. A IA também pode ser utilizada para analisar grandes volumes de dados, desenvolver modelos preditivos e ajudar a identificar novos padrões e tendências. A ciência está prestes a ser transformada de uma vez por todas pela inteligência artificial, e é importante que os cientistas continuem a se preparar para aproveitar ao máximo essa tecnologia e suas potenciais contribuições para a ciência.

Nesta Edição
    Os primeiros dois artigos desta edição tratam de estratégias discursivas da extrema direita, em que, enquanto o primeiro estudo investiga as violências verbal e física presentes no discurso autoritário de candidatos de direita, o segundo analisa como o problema das fake news se tornou cada vez mais grave durante a pandemia de Covid-19, especialmente quando se trata de informações relacionadas à saúde.
    No primeiro artigo desta edição, "Em que medida o autoritarismo e o discurso político violento influenciam a intenção de voto e o engajamento em campanha de candidatos de direita? Um experimento de vinhetas", Clayton Pereira Gonçalves e Eduardo Ayrosa abordam como alguns eleitores são influenciados por discursos agressivos e violentos de candidatos de direita. Os autores realizaram um experimento de vinhetas para avaliar o impacto do autoritarismo e do discurso político violento na intenção de voto e no engajamento em campanha desses candidatos. Os resultados mostraram que o discurso político violento diminui a intenção de voto, mas, quando mediado pela intenção de voto, gera maior engajamento na campanha do candidato. Além disso, os eleitores com maior grau de autoritarismo e maior interesse por política tendem a se engajar mais e ter maior intenção de voto.
    No segundo artigo, "O segundo artigo, "Fato ou fake? O organizar das redes de fake news sobre a pandemia de Covid-19", Carlos Dias Chaym, Maria Amélia Silva Gondim e Fábio da Silva realizaram um mapeamento


da rede de atores em torno de uma notícia divulgada em uma rede social aberta reconhecidamente falsa sobre a cura da Covid-19. Partindo de uma postagem inicial, que versa sobre uma receita sem comprovação científica acerca de um método de combate à Covid-19, os autores mapearam os desdobramentos da rede-de-atores humanos e não-humanos em torno de tal postagem. Os autores encontraram um engajamento exponencial em torno da notícia falsa, causando uma consequência incalculável para a saúde pública.
    O mundo das redes sociais também é explorado no terceiro artigo, "A carne é fraca: humor como denúncia", em que Cintia Rodrigues de Oliveira e Rafael Alcadipani documentaram as manifestações de internautas nas redes sociais online após a operação "carne fraca", conduzida pela Polícia Federal. Eles queriam compreender como o humor foi utilizado nas manifestações contra supostas ações criminosas de corporações, especialmente aquelas que poderiam afetar os usuários das redes sociais online, que podem ser consumidores dessas empresas. Ao analisar os memes compartilhados nas redes sociais Facebook e WhatsApp, Cintia e Rafael descobriram que os memes representaram uma estratégia de resistência discursiva contra os crimes corporativos, expressa por meio do humor como uma forma de denunciar as corporações, a nossa vulnerabilidade diante delas e o marketing corporativo.
    No quarto artigo desta edição, intitulado "A evolução crescente das pesquisas sobre empreendedorismo que tratam de afeto", Xênia L'amour Campos Oliveira e Eduardo Davel examinam o potencial do afeto para o avanço do conhecimento em empreendedorismo. Por meio de uma revisão sistemática de produções acadêmicas sobre o tema, os autores buscam construir um panorama integrado da produção acadêmica sobre empreendedorismo e afeto, identificando novas perspectivas para orientar o desenvolvimento de pesquisas futuras. Os resultados dessa pesquisa fornecem um conhecimento atualizado e integrado sobre o papel do afeto no empreendedorismo, bem como perspectivas para estimular e orientar pesquisas futuras a partir de uma discussão sobre desafios atuais, teorias do afeto e contextos do empreendedorismo.
    O quinto artigo desta edição, "As resistências ao mercado de alimentos transgênicos efetuadas pelo Greenpeace e Instituto Brasileiro de Defesa do Consumidor", de autoria de Rosana Oliveira Silva e Denise Franca Barros, examina as ações de resistência ao mercado de alimentos transgênicos realizadas pelo Greenpeace e pelo Instituto Brasileiro de Defesa do Consumidor. A pesquisa é qualitativa e utiliza dados coletados de matérias da Folha de S. Paulo, do O Estado de S. Paulo e dos sites das duas organizações, no período de 1998 a 2020, que foram analisados por meio da técnica da análise temática. Os resultados mostram muitas ações ao longo dos anos, dirigidas ao governo, às empresas, ao judiciário e aos consumidores individuais, e que visavam impedir o mercado de alimentos transgênicos. A pesquisa também destaca a importância da articulação das organizações com atores distintos para o sucesso dessas ações.


    Já no sexto artigo da edição, "Estéticas da existência indie: articulações em torno da concepção do mainstream", de Rodrigo César Tavares Cavalcanti, André Luiz Maranhão de Souza-Leão e Bruno Melo Moura, é examinado como os fãs de música indie interagem e discutem para definir o gênero, caracterizando-se como prossumidores (consumidores que atuam produtivamente sobre o que consomem). A pesquisa foi realizada por meio de uma netnografia em uma das principais comunidades virtuais de fãs do gênero e os resultados indicam o exercício de duas estéticas: uma que apresenta o indie como alternativa ao mainstream, baseada em concepções de liberdade e resistência; e outra que atesta o indie como aderente ao mainstream, graças à capacidade de ampliação do acesso ao gênero. Apesar de parecerem inconciliáveis, estas estéticas se fundam no entendimento de que o indie é belo e precisa ser preservado a partir de sua relação com a concepção do mainstream.
    No sétimo e último artigo da edição, "Aprender a reciclar: um olhar sobre as práticas de trabalho", Vanessa de Campos Junges, Simone Alves Pacheco de Campos e Rúbia Goi Becker, investiga-se como a prática do trabalho coletivo da reciclagem é compreendida, produzida e reproduzida por meio de um estudo de caso em uma associação de reciclagem. A pesquisa foi realizada usando técnicas etnográficas e análise textual, e os resultados mostram que os praticantes ressignificam essa prática pela negociação e reflexão, alterando o fluxo da ação anterior e legitimando um novo conjunto de normas que é reconhecido por todos. As autoras concluem que o modo de organização e aprendizado dos recicladores permite a construção e reconstrução constante das práticas, o que incentiva os gestores a superar desafios de projetos sociais por meio da aprendizagem pela prática.
    Devemos destacar também que estamos felizes em anunciar que a RECADM foi reconhecida como um dos 10 periódicos de maior impacto nas áreas de Administração, Contabilidade e Turismo no Spell. Isso é uma conquista impressionante e um testemunho do esforço incansável de nossa equipe de editores, autores e revisores, que trabalharam juntos para produzir conteúdo de alta qualidade para a comunidade acadêmica.
    Este reconhecimento é uma prova do impacto que nosso periódico tem na comunidade acadêmica e um incentivo para continuarmos a oferecer conteúdo relevante e inovador. Acreditamos que esse reconhecimento também abrirá novas oportunidades para que nossos autores possam compartilhar seu trabalho em um escopo maior e para que nossos leitores possam ter acesso a informações e descobertas valiosas. Em resumo, estamos extremamente orgulhosos de nossa equipe e de nosso periódico e esperamos continuar a contribuir significativamente para a comunidade acadêmica nacional.
    Deve-se adicionar também que a RECADM foi recentemente classificada como A4 no Qualis Capes 2017-2020. Esse resultado, em nosso entendimento, ainda não reflete a qualidade da revista, pois acreditamos que a distorção na avaliação ocorreu devido ao uso do H5 do Google, que privilegia periódicos que publicam um maior volume de artigos. A RECADM


também foi injustamente prejudicada no Google Acadêmico por ter mudado de site, o que fez com que a revista não constasse na indexação durante os anos de 2017 e 2021, o que prejudicou o seu desempenho na avaliação. Com base no desempenho da RECADM nos últimos anos no Spell, acreditamos que é possível reverter esse quadro, pois o periódico apresenta elementos suficientes para ser classificado como A2 no Qualis.
    P.S: Todo o texto foi produzido pela inteligência artificial, mas ele se mostrou extremamente dependente das ideias selecionadas por mim e das minhas orientações e construções de conjunções textuais. Isso mostra como a inteligência artificial pode ser uma ferramenta poderosa, mas ainda precisa ser orientada e supervisionada pelo ser humano.


Desejamos a todos uma excelente leitura,


Luciano Rossoni
Editor da RECADM




Referências
ChatGPT Generative Pre-trained Transformer, & Zhavoronkov, A. (2022). Rapamycin in the context of Pascal's Wager: generative pre-trained transformer perspective. Oncoscience, 9, 82-84. https://doi.org/10.18632/oncoscience.571
Else, H. (2023). Abstracts written by ChatGPT fool scientists. Nature. https://doi. org/10.1038/d41586-023-00056-7
Hutson, M. (2022). Could AI help you to write your next paper? Nature, 611(7934), 192-193. https://doi.org/10.1038/d41586-022-03479-w
O'Connor, S., & ChatGPT (2023). Open artificial intelligence platforms in nursing education: Tools for academic progress or abuse? Nurse Education in Practice, 66, 103537-103537. https://doi.org/10.1016/j.nepr.2022.103537






